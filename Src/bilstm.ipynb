{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "ftraindf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/ftraindf.csv')\n",
    "fvaldf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/fvaldf.csv')\n",
    "ftestdf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/ftestdf.csv')\n",
    "\n",
    "with open('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/features_selected.pkl', 'rb') as handle:\n",
    "    features_selected = pickle.load(handle)\n",
    "\n",
    "selected_cluster = 1\n",
    "cluster_suffix = \"_c0\"  # Assumes all selected features have this suffix\n",
    "features = [f + cluster_suffix for f in features_selected[selected_cluster]] + ['yref_Tm0_close']\n",
    "\n",
    "ftraindf = ftraindf[features]\n",
    "fvaldf = fvaldf[features]\n",
    "ftestdf = ftestdf[features]\n",
    "\n",
    "# Combine for consistent scaling\n",
    "scaler = MinMaxScaler()\n",
    "all_data = pd.concat([ftraindf, fvaldf, ftestdf])\n",
    "scaled_all = scaler.fit_transform(all_data)\n",
    "\n",
    "# Split back\n",
    "train_len = len(ftraindf)\n",
    "val_len = len(fvaldf)\n",
    "test_len = len(ftestdf)\n",
    "\n",
    "train_scaled = scaled_all[:train_len]\n",
    "val_scaled = scaled_all[train_len:train_len+val_len]\n",
    "test_scaled = scaled_all[train_len+val_len:]\n",
    "\n",
    "# Sequence builder\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length][-1])  # Predicting 'Close'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 5\n",
    "X_train, y_train = create_sequences(train_scaled, SEQ_LENGTH)\n",
    "X_val, y_val = create_sequences(val_scaled, SEQ_LENGTH)\n",
    "X_test, y_test = create_sequences(test_scaled, SEQ_LENGTH)\n",
    "\n",
    "# Build BiLSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True), input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "zero_pad = np.zeros((len(y_pred_scaled), len(features)-1))\n",
    "y_pred_combined = np.hstack((zero_pad, y_pred_scaled))\n",
    "y_pred = scaler.inverse_transform(y_pred_combined)[:, -1]\n",
    "\n",
    "# Actual values\n",
    "y_true = ftestdf['yref_Tm0_close'].values[SEQ_LENGTH:]\n",
    "\n",
    "# Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"‚úÖ RMSE: {rmse:.4f}\")\n",
    "print(f\"‚úÖ R¬≤ Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "ftraindf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/ftraindf.csv')\n",
    "fvaldf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/fvaldf.csv')\n",
    "ftestdf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/ftestdf.csv')\n",
    "\n",
    "with open('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/features_selected.pkl', 'rb') as handle:\n",
    "    features_selected = pickle.load(handle)\n",
    "\n",
    "# Model parameters\n",
    "SEQ_LENGTH = 5\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "cluster_suffix = \"_c0\"  # consistent suffix in your dataset\n",
    "\n",
    "results = []\n",
    "\n",
    "for cluster_id in range(1, 14):  # Tp1 to Tp13\n",
    "    try:\n",
    "        print(f\"üîÅ Training cluster Tp{cluster_id}\")\n",
    "        \n",
    "        # Build feature set and subset data\n",
    "        features = [f + cluster_suffix for f in features_selected[cluster_id]] + ['yref_Tm0_close']\n",
    "        ft = ftraindf[features]\n",
    "        fv = fvaldf[features]\n",
    "        fs = ftestdf[features]\n",
    "\n",
    "        # Normalize\n",
    "        all_data = pd.concat([ft, fv, fs])\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_all = scaler.fit_transform(all_data)\n",
    "\n",
    "        train_len = len(ft)\n",
    "        val_len = len(fv)\n",
    "        test_len = len(fs)\n",
    "\n",
    "        train_scaled = scaled_all[:train_len]\n",
    "        val_scaled = scaled_all[train_len:train_len+val_len]\n",
    "        test_scaled = scaled_all[train_len+val_len:]\n",
    "\n",
    "        # Build sequences\n",
    "        def create_sequences(data, seq_length=5):\n",
    "            X, y = [], []\n",
    "            for i in range(len(data) - seq_length):\n",
    "                X.append(data[i:i+seq_length])\n",
    "                y.append(data[i+seq_length][-1])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        X_train, y_train = create_sequences(train_scaled, SEQ_LENGTH)\n",
    "        X_val, y_val = create_sequences(val_scaled, SEQ_LENGTH)\n",
    "        X_test, y_test = create_sequences(test_scaled, SEQ_LENGTH)\n",
    "\n",
    "        # Model\n",
    "        model = Sequential([\n",
    "            Bidirectional(LSTM(64, return_sequences=True), input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(64)),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "        # Inverse scale\n",
    "        zero_pad = np.zeros((len(y_pred_scaled), len(features)-1))\n",
    "        y_pred_combined = np.hstack((zero_pad, y_pred_scaled))\n",
    "        y_pred = scaler.inverse_transform(y_pred_combined)[:, -1]\n",
    "\n",
    "        y_true = fs['yref_Tm0_close'].values[SEQ_LENGTH:]\n",
    "\n",
    "        # Metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"‚úÖ Tp{cluster_id} ‚Üí RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")\n",
    "        results.append({\n",
    "            'Tp': f'Tp{cluster_id}',\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Tp{cluster_id} failed: {e}\")\n",
    "        results.append({\n",
    "            'Tp': f'Tp{cluster_id}',\n",
    "            'RMSE': None,\n",
    "            'R2': None,\n",
    "            'Error': str(e)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Training cluster Tp1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
      "‚úÖ Tp1 ‚Üí RMSE: 0.1016 | R¬≤: 0.4926\n",
      "üîÅ Training cluster Tp2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n",
      "‚úÖ Tp2 ‚Üí RMSE: 0.0403 | R¬≤: 0.9204\n",
      "üîÅ Training cluster Tp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "‚úÖ Tp3 ‚Üí RMSE: 0.0796 | R¬≤: 0.6887\n",
      "üîÅ Training cluster Tp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step\n",
      "‚úÖ Tp4 ‚Üí RMSE: 0.0750 | R¬≤: 0.7236\n",
      "üîÅ Training cluster Tp5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "‚úÖ Tp5 ‚Üí RMSE: 0.0489 | R¬≤: 0.8826\n",
      "üîÅ Training cluster Tp6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "‚úÖ Tp6 ‚Üí RMSE: 0.0360 | R¬≤: 0.9362\n",
      "üîÅ Training cluster Tp7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step\n",
      "‚úÖ Tp7 ‚Üí RMSE: 0.0943 | R¬≤: 0.5634\n",
      "üîÅ Training cluster Tp8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "‚úÖ Tp8 ‚Üí RMSE: 0.0599 | R¬≤: 0.8240\n",
      "üîÅ Training cluster Tp9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "‚úÖ Tp9 ‚Üí RMSE: 0.0891 | R¬≤: 0.6102\n",
      "üîÅ Training cluster Tp10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step\n",
      "‚úÖ Tp10 ‚Üí RMSE: 0.0628 | R¬≤: 0.8064\n",
      "üîÅ Training cluster Tp11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "‚úÖ Tp11 ‚Üí RMSE: 0.1295 | R¬≤: 0.1755\n",
      "üîÅ Training cluster Tp12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "‚úÖ Tp12 ‚Üí RMSE: 0.1038 | R¬≤: 0.4701\n",
      "üîÅ Training cluster Tp13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priya/.local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "‚úÖ Tp13 ‚Üí RMSE: 0.0391 | R¬≤: 0.9249\n",
      "\n",
      "üìä Summary:\n",
      "      Tp      RMSE        R2\n",
      "0    Tp1  0.101627  0.492555\n",
      "1    Tp2  0.040253  0.920388\n",
      "2    Tp3  0.079593  0.688739\n",
      "3    Tp4  0.075000  0.723628\n",
      "4    Tp5  0.048880  0.882610\n",
      "5    Tp6  0.036021  0.936250\n",
      "6    Tp7  0.094264  0.563419\n",
      "7    Tp8  0.059854  0.823980\n",
      "8    Tp9  0.089069  0.610220\n",
      "9   Tp10  0.062766  0.806441\n",
      "10  Tp11  0.129539  0.175532\n",
      "11  Tp12  0.103850  0.470118\n",
      "12  Tp13  0.039096  0.924899\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "ftraindf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/benchmark_C38U.SI_traindf.csv')\n",
    "fvaldf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/benchmark_C38U.SI_valdf.csv')\n",
    "ftestdf = pd.read_csv('/home/priya/Desktop/fyp/Src alwin/Src/benchmark_C38U.SI_testdf.csv')\n",
    "\n",
    "\n",
    "with open('/home/priya/Desktop/fyp/Src alwin/Src/data/C38U.SI/features_selected.pkl', 'rb') as handle:\n",
    "    features_selected = pickle.load(handle)\n",
    "\n",
    "# Model parameters\n",
    "SEQ_LENGTH = 5\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "cluster_suffix = \"_c0\"  # consistent suffix in your dataset\n",
    "\n",
    "results = []\n",
    "\n",
    "for cluster_id in range(1, 14):  # Tp1 to Tp13\n",
    "    try:\n",
    "        print(f\"üîÅ Training cluster Tp{cluster_id}\")\n",
    "        \n",
    "        # Build feature set and subset data\n",
    "        features = features_selected[cluster_id] + ['yref_Tm0_close']\n",
    "\n",
    "        ft = ftraindf[features]\n",
    "        fv = fvaldf[features]\n",
    "        fs = ftestdf[features]\n",
    "\n",
    "        # Normalize\n",
    "        all_data = pd.concat([ft, fv, fs])\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_all = scaler.fit_transform(all_data)\n",
    "\n",
    "        train_len = len(ft)\n",
    "        val_len = len(fv)\n",
    "        test_len = len(fs)\n",
    "\n",
    "        train_scaled = scaled_all[:train_len]\n",
    "        val_scaled = scaled_all[train_len:train_len+val_len]\n",
    "        test_scaled = scaled_all[train_len+val_len:]\n",
    "\n",
    "        # Build sequences\n",
    "        def create_sequences(data, seq_length=5):\n",
    "            X, y = [], []\n",
    "            for i in range(len(data) - seq_length):\n",
    "                X.append(data[i:i+seq_length])\n",
    "                y.append(data[i+seq_length][-1])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        X_train, y_train = create_sequences(train_scaled, SEQ_LENGTH)\n",
    "        X_val, y_val = create_sequences(val_scaled, SEQ_LENGTH)\n",
    "        X_test, y_test = create_sequences(test_scaled, SEQ_LENGTH)\n",
    "\n",
    "        # Model\n",
    "        model = Sequential([\n",
    "            Bidirectional(LSTM(64, return_sequences=True), input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(64)),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "        # Inverse scale\n",
    "        zero_pad = np.zeros((len(y_pred_scaled), len(features)-1))\n",
    "        y_pred_combined = np.hstack((zero_pad, y_pred_scaled))\n",
    "        y_pred = scaler.inverse_transform(y_pred_combined)[:, -1]\n",
    "\n",
    "        y_true = fs['yref_Tm0_close'].values[SEQ_LENGTH:]\n",
    "\n",
    "        # Metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"‚úÖ Tp{cluster_id} ‚Üí RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")\n",
    "        results.append({\n",
    "            'Tp': f'Tp{cluster_id}',\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Tp{cluster_id} failed: {e}\")\n",
    "        results.append({\n",
    "            'Tp': f'Tp{cluster_id}',\n",
    "            'RMSE': None,\n",
    "            'R2': None,\n",
    "            'Error': str(e)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
